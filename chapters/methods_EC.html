
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Interpretable Models &#8212; Interpretable AI for wetland and coastal sedimentation analysis</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Brief Data Descriptions" href="data_EC.html" />
    <link rel="prev" title="Introduction" href="motivation_EC.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/GeoSMART_logo.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Interpretable AI for wetland and coastal sedimentation analysis</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://geo-smart.github.io/index.html">
   Geosmart Website
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://foundations.projectpythia.org/landing-page.html">
   Project Pythia Foundations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="about.html">
   About Use Case Library
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter One
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="motivation_EC.html">
   Introduction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Two
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Interpretable Models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Three
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="data_EC.html">
   Brief Data Descriptions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Five
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="training_EC.html">
   Bayesian Ridge Regression Implementation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Six
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="evaluation_EC.html">
   SHAP Analysis
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Seven
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="workflow.html">
   Workflow Management / Cloud Computing
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Eight
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Reproducibility_EC.html">
   Reproducibility
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Nine
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="conclusion_EC.html">
   Conclusion
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Ten (optional)
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="todo.html">
   Try something on your own
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Eleven (optional)
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="questions.html">
   Open questions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Twelve (optional)
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="troubleshooting.html">
   Trouble Shooting
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Thirteen
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="example.html">
   Sample Jupyter Notebook
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../reference/glossary.html">
   Glossaries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reference/bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/geo-smart/xai_sedimentation_use_case_book/main?urlpath=lab/tree/book/chapters/methods_EC.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/geo-smart/xai_sedimentation_use_case_book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/geo-smart/xai_sedimentation_use_case_book/issues/new?title=Issue%20on%20page%20%2Fchapters/methods_EC.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/geo-smart/xai_sedimentation_use_case_book/edit/main/book/chapters/methods_EC.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/chapters/methods_EC.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Interpretable Models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-regression">
     Linear Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regularized-linear-regression">
     Regularized Linear Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-linear-regression-blr">
     Bayesian Linear Regression (BLR)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-and-frequenist-regularized-linear-regression-have-the-same-solution">
     Bayesian and Frequenist Regularized Linear Regression have the same solution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applying-a-nonlinear-model">
   Applying a Nonlinear Model
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gaussian-process-regression">
     Gaussian Process Regression
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Interpretable Models</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Interpretable Models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-regression">
     Linear Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regularized-linear-regression">
     Regularized Linear Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-linear-regression-blr">
     Bayesian Linear Regression (BLR)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-and-frequenist-regularized-linear-regression-have-the-same-solution">
     Bayesian and Frequenist Regularized Linear Regression have the same solution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applying-a-nonlinear-model">
   Applying a Nonlinear Model
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gaussian-process-regression">
     Gaussian Process Regression
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="interpretable-models">
<h1>Interpretable Models<a class="headerlink" href="#interpretable-models" title="Permalink to this headline">#</a></h1>
<p>Every machine learning model is interpretable in some way or another, however, simpler models are much easier to interpret. Many top performing models, such as Artificial Neural Networks, Convolutional Neural Networks, and ensemble tree based models are not readily interpretable. Their lack of interpretability can discourage scientists from using them, which limits the tool set of a scientific investigator. But, there are also less popular but equally well performing models that are interpretable out there. We will discuss two types of models, a Bayesian Linear Regression and a Gaussian Process Regression, that both have analytical solutions for the conditional probability of our target variable.</p>
<p><a id='_linear_regressions'></a></p>
<section id="linear-regression">
<h2>Linear Regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">#</a></h2>
<p>First, let’s start with how a linear regression operates.</p>
<p>A linear regression is one of the most interpretable machine learning models to implement. The approach to approximate an unknown function, <span class="math notranslate nohighlight">\(f(x)\)</span>, using a linear regression assumes that <span class="math notranslate nohighlight">\(f(x)\)</span> is a linear combination of the input features, <span class="math notranslate nohighlight">\(X\)</span>, such that
$<span class="math notranslate nohighlight">\(f(x,w)= \sum^N_{i=1} w_i x_i \)</span>$
Equation 1</p>
<p>where <span class="math notranslate nohighlight">\(w\)</span> is the unknown parameter known as the weight vector, <span class="math notranslate nohighlight">\(N\)</span> is the number of predictors, and <span class="math notranslate nohighlight">\(x\)</span> are the input features. A more familiar writing of the above equation can look like:
$<span class="math notranslate nohighlight">\( y=w_0+w_1 x_1+⋯+w_N x_N \)</span>$
Equation 2</p>
<p>This is called a parametric machine learning model because we assume the form of the function we are trying to approximate, a linear form. The one parameter an ordinary linear model needs to learn is the weight vector <span class="math notranslate nohighlight">\(w\)</span>. This vector determines the influence of each of the input predictors, in our case environmental variables, that influence the target, vertical accretion. To solve for the optimal weight vector, we need to take the most likely set of maximum likelihood of the target <span class="math notranslate nohighlight">\(y\)</span> given a linear combination of <span class="math notranslate nohighlight">\(w X\)</span>. To do this, we first write the likelihood function generally</p>
<div class="math notranslate nohighlight">
\[p(y | X, w, \beta) = \prod \mathcal{N}(y_n | w^T x_n , \beta^-{1})\]</div>
<p>Equation 3</p>
<p>Where <span class="math notranslate nohighlight">\(\beta\)</span> is the noise associated with the target. Now, given our training data we want to find the <span class="math notranslate nohighlight">\(w\)</span> parameter that maximizes this equation, the likelihood of <span class="math notranslate nohighlight">\(y\)</span>. To do this, we need to take teh logarithm of the equation, then the derivative, then set the equation to zero, and solve for <span class="math notranslate nohighlight">\(w\)</span>.</p>
<p>Then solving for <span class="math notranslate nohighlight">\(w\)</span> we get</p>
<div class="math notranslate nohighlight">
\[w = (X^T X)^{-1} X^T y\]</div>
<p>Equation 4</p>
<p>This is the learned optimal set of the weight vector and is obtained from the Gauss-Markov Theorem.</p>
</section>
<section id="regularized-linear-regression">
<h2>Regularized Linear Regression<a class="headerlink" href="#regularized-linear-regression" title="Permalink to this headline">#</a></h2>
<p>Both a classic linear regression and a Bayesian linear regression can be modified to mitigate the effects of overfitting to the training data. Overfitting is when our model places undue importance to certain features, commonly occurring when given many input features. The effect is that we perfectly fit to our training data, making our model perform poorly when given new data. A visualization can be seen below.</p>
<p><img alt="image-4.png" src="chapters/attachment:image-4.png" /></p>
<p>To combat overfitting, a regularization term is employed. The term can either be an L1 or L2 regularization term and it is subsequently added to the sum of squares error equation <span class="math notranslate nohighlight">\(\sum_{i=1}^{N} (y_i - w^T x_i)^2\)</span>, such that the new total error equation becomes either</p>
<p>L1 regularized sum of square errors:
$<span class="math notranslate nohighlight">\( \sum_{i=1}^{N} (y_i - w^T x_i)^2 + \frac{\lambda}{2}|w| \)</span>$
Equation 5</p>
<p>L2 regularized sum of square errors:
$<span class="math notranslate nohighlight">\( \sum_{i=1}^{N} (y_i - w^T x_i)^2 + \frac{\lambda}{2} w^T w \)</span>$
Equation 6</p>
<p>As we can see, <span class="math notranslate nohighlight">\(\lambda\)</span> is an important term determining how much to penalize large weight coefficients. In a Frequentist framework this term has to be defined explicitly by the investigator or through a cross validation technique that tests various possible values for <span class="math notranslate nohighlight">\(\lambda\)</span> and selects the value which minimizes testing error. Cross validation is a machine learning model evaluation method in which a dataset is split into <span class="math notranslate nohighlight">\(K\)</span> folds, then the model is trained on <span class="math notranslate nohighlight">\(K-1\)</span> folds, then tested on the remaining one fold where some error metric is computed. This is then repeated <span class="math notranslate nohighlight">\(K\)</span> times, alternating the fold in which we test on, and the calculated model errors are then averaged. A schematic is shown below</p>
<p><img alt="image-5.png" src="chapters/attachment:image-5.png" /></p>
<p>When a proper <span class="math notranslate nohighlight">\(\lambda\)</span> value is found, we then apply the same process for the solution of the best weight vector as we did for the ordinary linear regression to get:</p>
<div class="math notranslate nohighlight">
\[w = (\lambda I + X^T X)^{-1} X^T y\]</div>
<p>Equation 7</p>
<p>This then becomes the optimal weight vector for a regularized linear regression.</p>
<p><a id='_BLR'></a></p>
</section>
<section id="bayesian-linear-regression-blr">
<h2>Bayesian Linear Regression (BLR)<a class="headerlink" href="#bayesian-linear-regression-blr" title="Permalink to this headline">#</a></h2>
<p>A Bayesian linear regression is simply a reformulation of the classic, Frequentist linear regression explained above from a Bayesian perspective. The only difference is that the Bayesian perspective deals with probabilities in the form of distributions rather than point estimations. Therefore, both the Frequentist and Bayesian treatment of linear regression have the same tractable solution to the conditional probability of our target variable (Bishop 2006). This is preferable from a scientific perspective when making conclusions from the learned weight parameters and building confidence in our model’s predictions.</p>
<p>To find the weight vector from a Bayesian perspective we take the log derivative of the posterior distribution of <span class="math notranslate nohighlight">\(w\)</span>, which is the product of the prior and the likelihood functions over <span class="math notranslate nohighlight">\(w\)</span>. The log of the posterior follows similarly to the regularized sum of square errors equations (Bishop 2006).
$<span class="math notranslate nohighlight">\( \ln p(w|X, y) = -\frac{\beta}{2} \sum_{i=1}^N(y_i - w^T x_i)^2 - \frac{\alpha}{2} w^T w \)</span>$
Equation 8</p>
<p>Where <span class="math notranslate nohighlight">\(\beta\)</span> is the noise parameter over y, the target variable from the train set, and <span class="math notranslate nohighlight">\(\alpha\)</span> is the precision, or noise, over the weight parameter. <span class="math notranslate nohighlight">\(X\)</span> is the data in the design matrix. We then maximize the log posterior with respect to <span class="math notranslate nohighlight">\(w\)</span> by taking the derivative, setting to zero, and solving for <span class="math notranslate nohighlight">\(w\)</span> to find the most likely <span class="math notranslate nohighlight">\(w\)</span> vector.</p>
<p>From further inspection of the equation, we see that <span class="math notranslate nohighlight">\(\alpha / \beta\)</span> act the same as <span class="math notranslate nohighlight">\(\lambda\)</span> in the L2 regularized solution. This is where an advantage of the Bayesian treatment arises because all we need to do is find the values for <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> to get the regularization parameter <span class="math notranslate nohighlight">\(\lambda\)</span>. This can be done through a technique called <em>Empirical Bayes</em> with an iterative algorithm. Another advantage of the Bayesian treatment is that, by dealing with distributions, model uncertainty quantification can be readily attained through the standard deviation of the predictive distribution and from the eigen decomposition of matrix of feature inputs (Bishop 2006, MacKay 1992).</p>
</section>
<section id="bayesian-and-frequenist-regularized-linear-regression-have-the-same-solution">
<h2>Bayesian and Frequenist Regularized Linear Regression have the same solution<a class="headerlink" href="#bayesian-and-frequenist-regularized-linear-regression-have-the-same-solution" title="Permalink to this headline">#</a></h2>
<p>Just to solidify the notion that the both an L2 regularized linear regression for a Bayesian and Frequentist persepctive have the same solution, we are going to implement both types of L2 linear regression using scikit-learn. In scikit-learn’s library, the Ridge regression is the Frequentist L2 regularized linear regression and the Bayesian Ridge regression is the Bayesian L2 regularized linear regression. In the below cells we will implement meant them both.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Testing whether the scikit learn ridge and bayesian ridge learn the same paramters</span>
<span class="n">olsr</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">Ridge</span><span class="p">()</span>
<span class="n">br</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">BayesianRidge</span><span class="p">()</span>

<span class="c1"># We need to hyperparamter tune the OLS Ridge because there is no way to solve for the regularization parameter analytically</span>
<span class="n">searcher</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">olsr</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">2</span><span class="p">)},</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_root_mean_squared_error&quot;</span><span class="p">)</span>
<span class="n">searcher</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="s1">&#39;Tidal Amplitude (cm)&#39;</span><span class="p">,</span> <span class="s1">&#39;Avg. Flood Depth (cm)&#39;</span><span class="p">]],</span> <span class="n">target</span><span class="p">)</span>
<span class="n">best_olsr</span> <span class="o">=</span> <span class="n">searcher</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best regularizor by Cross Validation: &quot;</span><span class="p">,</span> <span class="n">searcher</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Learned Weight Coefficents: &quot;</span><span class="p">,</span> <span class="n">best_olsr</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best regularizor by Cross Validation:  {&#39;alpha&#39;: 1}
Learned Weight Coefficents:  [3.90306258 1.13199355]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fit the br and see if it is the same</span>
<span class="n">br</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="s1">&#39;Tidal Amplitude (cm)&#39;</span><span class="p">,</span> <span class="s1">&#39;Avg. Flood Depth (cm)&#39;</span><span class="p">]],</span> <span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Learned Regularizor: &quot;</span><span class="p">,</span> <span class="n">br</span><span class="o">.</span><span class="n">lambda_</span> <span class="o">/</span> <span class="n">br</span><span class="o">.</span><span class="n">alpha_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Learned Weight Coefficent: &quot;</span><span class="p">,</span> <span class="n">br</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Learned Regularizor:  3.433346530743498
Learned Weight Coefficent:  [3.8591872  1.10676778]
</pre></div>
</div>
</div>
</div>
<p>From the weight coefficients and learned regularizers, we can see that the two methods produce similar results. While the only difference arises from the learned regularization term. We are able to find the Bayesian Ridge Regression solves for a higher regularization term of 3.44 through the Empirical Bayes method, while the cross-validation of the OLS Ridge Regression finds an optimal regularization term value of 1.</p>
<p><a id='_GPR'></a></p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="applying-a-nonlinear-model">
<h1>Applying a Nonlinear Model<a class="headerlink" href="#applying-a-nonlinear-model" title="Permalink to this headline">#</a></h1>
<section id="gaussian-process-regression">
<h2>Gaussian Process Regression<a class="headerlink" href="#gaussian-process-regression" title="Permalink to this headline">#</a></h2>
<p>The GPR begins with our desire to find an unknown function <span class="math notranslate nohighlight">\(f(x)\)</span> that will help us predict our target variable <span class="math notranslate nohighlight">\(y\)</span> with the addition of some Gaussian distributed noise, <span class="math notranslate nohighlight">\(\epsilon\)</span>, such that:
$<span class="math notranslate nohighlight">\( y = f(x)+ \epsilon \)</span>$
Equation 11</p>
<p>The BLR approach falls short when the relationship between our input and output variables is nonlinear, due to defining our unknown function as a linear combination of the predictors governed by the learned weight parameter, <span class="math notranslate nohighlight">\(w\)</span>. A Gaussian Process Regression (GPR) overcomes the limited flexibility of the BLR by projecting the inputs into an infinitely high dimensional space using a set of basis functions which allow us to overcome the assumption of linearity in a BLR (Rasmussen and Williams 2005). This makes GPR a powerful non-parametric machine learning tool that can capture the nonlinear dynamics and interactions of the input and output variables.</p>
<p>The reasoning behind a GPR includes using a Gaussian Process to describe the distribution over all possible functions for a given sample <span class="math notranslate nohighlight">\(x_i\)</span>. Defined as a collection of random variables of which any finite set have a joint Gaussian distribution, a Gaussian process can be completely specified by its mean function, <span class="math notranslate nohighlight">\(m(x)\)</span>, and covariance function, <span class="math notranslate nohighlight">\(k(x,x')\)</span> (Rasmussen and Williams 2005). Following Rasmussen and Williams 2005, with a known mean and covariance, we can write the prior distribution of all possible random unknown functions as:
$<span class="math notranslate nohighlight">\( f(x)∼GP(m(x),k(x,x')) \)</span>$
Equation 12</p>
<p>An important choice for the investigator is choosing the covariance function, <span class="math notranslate nohighlight">\(k(⋅,⋅)\)</span>, for the GPR model that best describes our data. In broad sense, we expect similar samples to have similar outcomes and effects on the target variable and the covariance function is what defines the similarity between samples. After multiple trials, we deduce that a squared dot product covariance function fits our data best.<br />
$<span class="math notranslate nohighlight">\( k(x,x' )=(x \cdot x' )^2+\delta\)</span>$
Equation 13</p>
<p>Where <span class="math notranslate nohighlight">\(\delta\)</span> is the error associated with the target variable and <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(x'\)</span> are predictors.</p>
<p>From a specified mean and covariance function, the computation of the conditional probability of our target is straight forward. Assuming a zero mean we can write:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix} y \\ f_* \end{bmatrix} = \mathcal{N} ( \begin{bmatrix} 0 \\ 0 \end{bmatrix} , \begin{bmatrix} (k(X,X)+σ^2I &amp; k(X,X_*) \\ k(X_*,X) &amp; k(X_*,X_*) \end{bmatrix} )\end{split}\]</div>
<p>Equation 14</p>
<p>Where <span class="math notranslate nohighlight">\(k(X,X)\)</span> is the covariance between training samples, <span class="math notranslate nohighlight">\(k(X_*,X_*)\)</span> is the covariance between testing samples, <span class="math notranslate nohighlight">\(k(X_*,X)\)</span> and <span class="math notranslate nohighlight">\(k(X,X_*)\)</span> are the covariances between training and testing samples, <span class="math notranslate nohighlight">\(y\)</span> is the target variable, <span class="math notranslate nohighlight">\(f_*\)</span> is the learned function, and <span class="math notranslate nohighlight">\(\sigma^2\)</span> is the noise associated with the target variable (Rasmussen and Williams 2005). Utilizing the rules for the combination of partitioned Gaussians we can write the mean and covariance for the predictive distribution as
$<span class="math notranslate nohighlight">\( m(x)=k(X_*,X)(k(X,X)+ σ^2 I)^{-1} y \)</span>$
Equation 15</p>
<div class="math notranslate nohighlight">
\[ k(x,x') = k(X_*,X_* ) - k(X_*, X)(k(X,X)+ σ^2 I)^{-1} k(X,X_*) \]</div>
<p>Equation 16</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="motivation_EC.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introduction</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="data_EC.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Brief Data Descriptions</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By EChenevert<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>