{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e815d41",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The above tutorial explains how we can implement interpretable machine learning models that perform highly on small datasets common in the earth sciences. For such a complex marsh system like that of coastal Louisiana, a nonlinear model, the Gaussian Process Regression, outperforms the linear model by about 10%. To better understand interactions and outcome dependence on predictors in the Gaussian Process Regression, we utilize the SHAP python explainability package to better understand variable interactions. The SHAP workflow that we employ here can be extended to other complex machine learning models such as GANs, random forests, and etc. \n",
    "\n",
    "While there is much more to be explored regarding the mechanisms of sedimentation in a marsh system, our machine learning workflow has elucidated some of the dominant relationships of environmental variables contributing to vertical accretion rates. Primarily the influence of tidal amplitude and the 90th percentile of flood depth on the predictive power of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61500bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
